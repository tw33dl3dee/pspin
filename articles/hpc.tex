\documentclass[12pt,a4paper,fleqn]{article}

\usepackage{ucs}
\usepackage[utf8x]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[english,russian]{babel}

\usepackage{textcomp}
\usepackage{indentfirst}
\usepackage{verbatim}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
%\usepackage[colorlinks, urlcolor=blue, pdfborder={0 0 0 [0 0]}]{hyperref}
\usepackage{cmap}       % теперь из pdf можно копипастить русский текст
\usepackage{underscore} % Ура! Теперь можно писать подчёркивание.
\usepackage{graphicx}	% Пакет для включения рисунков

\usepackage[left=20mm,right=20mm,top=20mm,bottom=20mm]{geometry}

\IfFileExists{cyrtimes.sty}
{
  \usepackage{cyrtimespatched}
} 
{
  % А если Times нету, то будет CM...
}

\usepackage{color}

\usepackage{listings}
% Значения по умолчанию для listings
\lstset{
  basicstyle=\footnotesize,
  frame=none,
  breakatwhitespace=true,% разрыв строк только на whitespacce
  breaklines=true,       % переносить длинные строки
  captionpos=b,          % подписи снизу
  numbers=none,          % без нумерации
  showspaces=false,      % показывать пробелы подчеркиваниями -- идиотизм 70-х годов
  showstringspaces=false,
  showtabs=false,        % и табы тоже
  stepnumber=1,
  tabsize=4              % кому нужны табы по 8 символов?..
}

% Стиль для псесдовода: строчки обычно короткие, поэтому размер шрифта побольше
\lstdefinestyle{pseudocode}{
  basicstyle=\small,
  frame=none,
  keywordstyle=\color{black}\bfseries\underbar,
  language=Pseudocode,
  numberstyle=\footnotesize,
  commentstyle=\footnotesize\it
}

% Стиль для обычного кода: маленький шрифт
\lstdefinestyle{realcode}{
  basicstyle=\scriptsize,
  frame=none,
  numberstyle=\footnotesize
}

% Стиль для коротких кусков обычного кода: средний шрифт
\lstdefinestyle{simplecode}{
  basicstyle=\footnotesize,
  frame=none,
  numberstyle=\footnotesize
}

% Определим свой язык для написания псевдокодов на основе Python
\lstdefinelanguage[]{Pseudocode}[]{Python}{
  morekeywords={each,empty,wait,do},% ключевые слова добавлять сюда
  morecomment=[s]{\{}{\}},% комменты {а-ля Pascal} смотрятся нагляднее
  literate=% а сюда добавлять операторы, которые хотите отображать как мат. символы
    {->}{\ensuremath{$\rightarrow$}~}2%
    {<-}{\ensuremath{$\leftarrow$}~}2%
    {:=}{\ensuremath{$\leftarrow$}~}2%
    {<--}{\ensuremath{$\Longleftarrow$}~}2%
}[keywords,comments]

\sloppy
\hyphenpenalty=9000

\makeatletter
\renewcommand\@biblabel[1]{\hfill#1.}
\makeatother

\newcommand\regsign{\textsuperscript{\textcircled{\scriptsize{R}}}}
\newcommand\copysign{\textsuperscript{\copyright}}
\newcommand\tmsign{\textsuperscript{\scriptsize{TM}}}

\newcommand{\Code}[1]{\textbf{\mbox{#1}}}
\newcommand{\Term}[1]{\emph{\mbox{#1}}}

\usepackage{alltt}

\newenvironment{CodeBlock}{\begin{alltt}\small}{\end{alltt}}

\DeclareMathOperator*{\StateTransN}{\Rightarrow}
\DeclareMathOperator{\StateTrans}{\StateTransN^T}

\newcommand\etc{~и~т.д.}
\newcommand\etca{~и~т.п.}

\title{Описание заявки на конкурс HPC Contest 2010: Parallel Spin}
\author{Коротков\,И.\,А.}

\begin{document}

  % a.. описание задачи; 
  % b.. требования к вычислительным ресурсам при ее решении в настоящее время; имеющиеся подходы к решению (уже разработанные); 
  % c.. суть предлагаемого проекта - что сделано/будет сделано в результате проекта; 
  % d.. сравнение с имеющимися подходами и преимущества; 
  % e.. обоснование необходимости и эффективности применения суперкомпьютеров для расчетов в предлагаемых для конкурса проектах; 
  % f.. описание методов, с помощью которых достигается эта эффективность; 
  % g.. перспективы использования, ожидаемая эффективность от внедрения приложения, практическое применение, потенциальные потребители. 

\section{Описание задачи}

При разработке сложных параллельных систем (систем, состоящих из нескольких асинхронно работающих
компонент) с высокой степенью надежности традиционных подходов к тестированию зачастую бывает
недостаточно, поскольку они позволяет выявить лишь легко воспроизводимые ошибки. В некоторых
случаях, например, в программном обеспечении для бортовых систем, определенные классы ошибок
требуется полностью исключить.

Для таких случаев применяется проверка модели (model checking)~--- автоматический
формальный подход, при котором на основе дискретной детерминированной модели программы или
комплекса программ строится полное пространство состояний и на нем проверяется набор
интересующих нас утверждений~--- спецификация. Проверку моделей можно использовать для
поиска взаимоблокировок в параллельных алгоритмах и ошибок в спецификациях сетевых
протоколов. В качестве примера можно привести протокол маршрутизации RIP: проверка модели
сети из четырех маршрутизаторов, соединенных четыремя сетевыми интерфейсами, на предмет
возникновения циклов в маршрутных таблицах позволяет убедиться, что существуют сценарии,
при которых такие циклы возникают, и необходимо использование специальных мер
(расщепленный горизонт) для их избежания.

Наиболее распространенным средством проверки конечных моделей является ПО SPIN,
использующее для описания исходной модели язык \emph{Promela} (PROtocol Meta Language).

Модель на языке Promela описывается в виде набора процессов, состоящих из последовательности
команд. Каждый процесс имеет свой набор локальных переменных (в том числе счетчик команд). Для
взаимодействия между процессами могут использоваться глобальные переменные и каналы (очереди
сообщений). Каждая команда имеет свое условие выполнимости, и процесс считается заблокированным,
если условие выполнимости его текущей команды не выполнено.

Пример описания модели семафора Дейкстры и трех захватывающих его процессов в нотации
Promela привен ниже:

\begin{lstlisting}[language=Promela]
mtype { p, v };
chan sema = [0] of { mtype };
active proctype Dijkstra()
{      byte count = 1;
       do
       :: (count == 1) ->
               sema!p; count--
       :: (count == 0) ->
               sema?v; count++
       od
}
active [3] proctype user()
{       do
        :: enter: sema?p;  /* enter critical section */
            crit: skip;    /* critical section */
                  sema!v;  /* leave critical section */
        od
}  
\end{lstlisting}

В ходе верификации SPIN выполняет исчерпывающий поиск в глубину по графу состояний и, при
обнаружении пути, на котором нарушается проверяемое утверждение, сохраняет его в качестве
контрпримера. Если контрпример обнаружить не удается, верификация успешна. Функциональная
схема процесса проверки модели изображена на рис.~\ref{fig:modelchk-idef0-a0}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{../graphics/modelchk-idef0-a0}
  \caption{Функциональная схема проверки модели}
  \label{fig:modelchk-idef0-a0}
\end{figure}

ПО Spin принимает в качестве входных данных модель многопоточной системы на языке Promela и
генерирует файл с кодом на языке С. Полученный код выполняет исчерпывающий поиск по пространству
состояний $S$ в глубину, добавляя посещенные состояния в хэш-таблицу, что можно представить
следующим псевдокодом:

\begin{lstlisting}[style=pseudocode]
Visited = []

def StateSpaceDFS(state):
    if not state in Visited:
        Visited <- state
        for each new_state in Next(state):
            StateSpaceDFS(new_state)

StateSpaceDFS(initial_state)
\end{lstlisting}

При генерации каждого состояния делается проверка, было ли оно уже посещено ранее (т.е. находится в
множестве \Code{Visited}) и добавление в этом множество в противном случае.

\section{Требования к вычислительным ресурсам}

Последовательное построение пространства состояний $S$ с ростом размера модели быстро становится
невозможным из-за нехватки памяти для хранения множества достигнутых состояний (\Code{Visited}). В
табл.~\ref{tab:models-statecount} приведены данные для двух моделей: модели задачи об обедающих
философов и более приближенной к реальным задачам модели RIP-протокола на 4 сетевых маршрутизаторах.

\begin{table}
  \centering
  \begin{tabular}{|r|l|l|}
    \hline
    Модель                  & Состояний         & Переходов       \\
    \hline
    Философы (5)            & $2.8 \cdot 10^4$  & $4.2 \cdot 10^4$ \\
    Философы (7)            & $3.6 \cdot 10^5$  & $6.0 \cdot 10^5$ \\
    RIP (4 маршрутизатора)  & $1.6 \cdot 10^8$  & $4.8 \cdot 10^9$ \\
    \hline
  \end{tabular}
  \caption{Количество состояний и переходов в различных моделях}
\label{tab:models-statecount}
\end{table}

Из табл. \ref{tab:models-statecount} видно, что для реальных моделей традиционный подход
становится проблематичен: к примеру, модель RIP-протокола с 5-ю маршрутизаторами потребует
уже более 100 Гб оперативной памяти для хранения пространства состояний.

\section{Существующие подходы к решению задачи}

Существует ряд подходов, решающих данную проблему. Среди них можно выделить:

\begin{itemize}
\item методы оптимизации, уменьшающие количество генерируемых и хранимых состояний;
\item методы оптимизации, уменьшающие расход памяти на хранение пространства состояний;
\end{itemize}

\textbf{Сокращение частных порядков} (\Term{partial order reduction}) относится к первой
группе: оно уменьшает количество генерируемых состояний. Данный метод использует тот факт,
что зачастую порядок выполнения двух переходов в различных процессах не оказывает влияния
на результат проверки, поэтому в случае двух независимых переходов, не меняющих
проверяемых свойств системы, генерируется лишь одна последовательность!!!

При \textbf{битовом хэшировании состояний} (\Term{bit-state hashing}) вместо традиционной
хэш-таблицы для хранения состояний используется битовая таблица. Каждое состояние $s$
представлено в ней битом с номером $i = hash(s)$. Нулевой бит означает, что состояние еще
не было достигнуто, единичный — было. При этом вся используемая память отводится под
хэш-таблицу (сами состояния не хранятся). При размере состояния в 20-30 байт это позволяет
хранить в 160-240 больше состояний, чем при традиционном подходе.

Однако, коллизии в этом случае обнаружить невозможно -- состояния будут просто <<теряться>>,
поэтому приходится просто полагаться на то, что коллизий не возникнет (для этого надо обеспечить
низкую степень заполненности таблицы) или что <<потерянные>> состояния не повлияют на итог. Такой
подход сильно снижает надежность получаемого результата, поэтому в чистом виде битовое хэширование
используется крайне редко.

\textbf{Сжатие состояние}, например, с использованием кодов Хаффмана, позволяет уменьшить требуемый
объем памяти в 4--5 раз за счет увеличения времени проверки.

Приведенные меры либо дают небольшой, плохо масштабируемый прирост, либо приводят к потенциальным потерям
состояний при обходе.

\section{Предлагаемый подход}

Альтернативным подходом является \emph{параллельная генерация состояний} с распределенным хранением
по различным узлам вычислительной сети.

Простейшим решением, практически не требующим принципиального изменения последовательного
алгоритма генерации, является распределенное хранение состояний: в этом случае состояния
генерирует головной узел, а для хранения используются все узлы. Головной узел при этом
может осуществлять поиск в глубину или в ширину точно таким же образом, как при
последовательном подходе, но при генерации каждого нового состояния $s'$ вычисляется номер
$i$ узла, хранящего $s'$, после чего делается удаленный вызов к этому узлу для проверки,
принадлежит ли это состояние множеству \Code{Visited} посещенных состояний. Каждый узел
имеет свою хэш-таблицу и память для хранения состояний.

На рис.~\ref{fig:distr-storage} показано, как в этом случае происходит хранение и
генерация состояний. Состояния обозначены кружками, финальные (<<тупиковые>>) состояния~---
обведенными кружками, переходы между ними~--- стрелками, удаленные вызовы между узлами~---
пунктирным стрелками. Цифры рядом с состояниями показывают порядок их генерации.

\begin{figure}[!htb]
  \centering 
  \includegraphics[width=0.4\textwidth]{../graphics/distr-storage}
  \caption{Пример работы алгоритма распределенного хранения}
  \label{fig:distr-storage}
\end{figure}

Псевдокод генерации состояний поиском в глубину с распределенным хранением выглядит
следующим образом (выполняется на головном узле):

\begin{lstlisting}[style=pseudocode]
Visited = []

def ParStateSpaceDFS(state):
    node = StateNode(state)
    if not state in node.Visited:
        node.Visited <- state
        for each new_state in Next(state):
            StateSpaceDFS(new_state)

ParStateSpaceDFS(initial_state)
\end{lstlisting}

Здесь \Code{StateNode}~--- функция, задающая отображение состояний на узлы (рассматривается
подробно далее), а \Code{node.Visited} представляет собой удаленный вызов к узлу
\Code{node}.

Недостатки приведенного алгоритма:
\begin{itemize}
\item используется вычислительная мощность лишь одного узла, остальные простаивают;
\item большое число удаленных вызовов;
\item удаленные вызовы синхронные (необходимо ждать ответа).
\end{itemize}

\subsection{Распределенная генерация состояний}
\label{sec:distr-generation}

Каждый узел является одновременно хранилищем и генератором и хранит очередь состояний
$Q$. Порождая новое состояние, узел $i$ проверяет, какому узлу оно принадлежит; если это
узел $j$, не совпадающий с данным ($i \neq j$), $i$ делает удаленный вызов $j$, в
результате которого состояние добавляется в очередь $Q_j$. Если состояние принадлежит тому
же узлу ($j = i$), он проверяет, не входит ли оно в множество посещенных состояний
\Code{Visited} и добавляет его в свою очередь $Q_i$. При этом каждый узел выполняет что-то
вроде поиска в ширину, однако какой-либо глобальный порядок обхода отсутствует~--- он не
соответствует ни обходу в ширину, ни обходу в глубину.

Порядок генерации того же набора состояний, что и в предыдущем примере, показан на
рис.~\ref{fig:distr-generation}. Цифры рядом с состояниями показывают локальный порядок их
генерации, в скобках~--- номера соответствующих состояний с рис.~\ref{fig:distr-storage}.

\begin{figure}[!htb]
  \centering
  \includegraphics[width=0.4\textwidth]{../graphics/distr-generation}
  \caption{Пример работы алгоритма распределенной генерации}
  \label{fig:distr-generation}
\end{figure}

Псевдокод, выполняемый на всех узлах:

\begin{lstlisting}[style=pseudocode]
Visited = []
Queue   = [initial_state]

def ParStateSpaceBFS():
    while not empty(Queue):
        Queue -> state
        node = StateNode(state)
        if NodeId = node:
            if not state in Visited:
                Visited <- state
                for each new_state in Next(state):
                    Queue <- new_state
        else:
            node.Queue <- state

ParStateSpaceBFS()
\end{lstlisting}

Здесь \Code{node.Queue $\leftarrow$ state}~--- удаленный вызов, добавляющий состояние в очередь узла
\Code{node}.

В отличие от распределенного хранения состояний:
\begin{itemize}
\item удаленные вызовы асинхронные: нет необходимости дожидаться ответа от узла, после
  отправки ему состояния можно продолжать генерацию;
\item возможен (описан далее) подбор такого распределения \Code{StateNode} между узлами,
  при котором число удаленных вызовов будет значительно меньше.
\end{itemize}

Поскольку глобальный порядок обхода состояний нарушается, поиск циклов, необходимый для проверки
условий <<живости>> становится затруднителен Поскольку нас интересуют лишь условия <<надежности>>,
сводимые к проверке утверждений относительно значений переменных в некоторых состояниях и к проверке
финальных состояний, распределенная генерация с поиском в ширину может использоваться без каких-либо
дальнейших модификаций.
!!!

В приведенном коде для определения номера узла, хранящего сообщения, используется функция
\Code{StateNode}. Обязательным требованием к этой функции является зависимость лишь от
самого состояния~--- если два различных узла, $i$ и $j$, сгенерируют одно и то же состояние
$s$, вычисленное на обоих узлах значение \Code{StateNode(s)} должно быть одинаковым.

\paragraph{Равномерность распределения}

Произвольным образом выбранное \Code{StateNode} может привести к тому, что состояния будут
распределены между узлами неравномерно, что приведет к трате памяти на одних узлах и
возможной нехватке на других. Поэтому вторым требованием к \Code{StateNode} является как
можно большая равномерность распределения состояний между узлами. 

Наиболее простым выходом является в качестве \Code{StateNode} использовать хэш-функцию от
всего состояния. Выбор подходящей хэш-функции может обеспечить распределение, близкое к
идеальному.

\paragraph{Локальность распределения}

!!!укоротить нахуй

Пусть число узлов — $N$, состояний — $S$, переходов между ними — $T$. В случае
равномерного распределения состояний между узлами при помощи хэш-функции вероятность того,
что следующее состояние будет принадлежать текущему узлу равняется
$\frac{1}{N}$. Следовательно, вероятность того, что потребуется удаленный вызов, равна $1
- \frac{1}{N}$, а среднее число удаленных вызовов в течение всей генерации составит
\begin{equation}
  \label{eq:nmsg-full-hash}
  M_1 = T \cdot (1 - \frac{1}{N}) ,
\end{equation}
что при больших значениях $N$ стремится с $T$. Как показывают эксперименты, количество
удаленных вызовов является одним из ключевых факторов, определяющих скорость генерации
состояний. Следовательно, третьим желаемым свойством \Code{StateNode} является локальность
получаемого распределения~--- новые состояния должны по возможности принадлежать тому же
узлу, которому принадлежало предыдущее.

Следует отметить, что подобная оптимизация применима лишь при использовании распределенной
генерации, но не распределенного хранилища состояний, описанного в
разделе~\ref{sec:distr-storage}. В последнем случае все состояния генерируются головным
узлом, который может хранить лишь $S/N$ состояний, поэтому вероятность удаленного вызова
при сохранении нового состояния всегда будет не меньше, чем в (\ref{eq:nmsg-full-hash}), и
приближается к $1$ с ростом числа узлов.

В данной работе предлагаются распределение состояний, обладающее свойством
локальности. Оно заключается в том, чтобы хэшировать не все состояние $s$, а состояние
(локальные переменные и $IP$) первых $\rho$ процессов $s$.

Пусть $P$ — число процессов в модели, $k$ — среднее число процессов, затрагиваемых
переходом (состояние которых меняется при переходе). $k > 1$, если возможна (атомарная)
передача сообщений между процессами, при которой сообщение меняют одновременно 2
процесса. $k < 2$, если в одном изменении состояния могут участвовать максимум 2 процесса,
как в языке Promela.

Если предположить, что каждый процесс участвует примерно в равной доле переходов, то для
произвольного наперед заданного процесса вероятность участия в данном переходе составит
$\frac{k}{P}$, а вероятность участия одного из первых $\rho$ процессов~--- $\frac{\rho\cdot
  k}{P}$. Если \Code{StateNode} отображает множество локальных состояний первых $\rho$
процессов на множество узлов равномерным образом, то, по аналогии с предыдущими
рассуждениями, вероятность удаленного вызова при изменении состояния процесса составит $1
- \frac{1}{N}$. Количество удаленных вызовов во всей модели, таким образом, равняется
\begin{equation}
  \label{eq:nmsg-firstproc-hash}
  M_2 = T \cdot \frac{k\cdot\rho}{P} \cdot (1 - \frac{1}{N})
\end{equation}
и с ростом $N$ стремится к $T \cdot \frac{k\rho}{P}$. При количестве процессов $P = 6-8$,
$\rho = 1$ и $k = 1.5$, т.е. когда половина переходов приходится на взаимодействия
процессов, получаем в $P/k = 4-5$ раз меньше удаленных вызовов, чем при хэшировании
состояния целиком.

Значение $\rho$ следует выбирать из баланса между равномерностью распределения состояний и
уменьшением числа удаленных вызовов: если число узлов $N$ достаточно велико, при малых
$\rho$ распределение скорее всего будет неравномерным, а при больших число удаленных
вызовов будет близко к~(\ref{eq:nmsg-full-hash}).

Обозначим $\Omega_i$ число возможных состояний (т.е. всех возможных комбинаций значений
локальных переменных и $IP$) процесса $P_i$. Тогда минимальное значение $\rho$ должно
выбираться таким, чтобы
\begin{equation}
  \label{eq:min-rho}
  \prod_{i = 1}^\rho{\Omega_i} \geq N,
\end{equation}
иначе число возможных значений \Code{StateNode} будет меньше $N$. Если все процессы
одинаковы (или приблизительно одинаковы) и имеют $\Omega$ состояний,~(\ref{eq:min-rho})
превращается в 
\begin{equation}
  \label{eq:min-rho-homo}
  \Omega^\rho \geq N.
\end{equation}

Следует отметить, что, поскольку $IP_i$ входит в \Code{StateNode}, $\Omega_i$ для типичной
модели не меньше 30--40, поэтому $\rho = 1$ может быть достаточно для необходимой
равномерности распределения (обусловленной имеющимся количеством узлов и объемом памяти на
них).

\section{Описание методов}

Каждый узел хранит множество посещенных состояний \Code{Visited}, текущую очередь \Code{Queue} и
хэш-таблицу для быстрого поиска состояний в \Code{Visited}. В зависимости от того, какой тип
хэширования выбран, состояния хранятся в них по-разному.

В данной работе рассматриваются два подхода: полное хэширование с открытой адресацией и
битовое хэширование с произвольным (задаваемым) число хэш-функций.

\subsection{Полное хэширование}

При полном хэшировании хэш-таблица хранит указатели на состояния в \Code{Visited}. Сами
состояния хранятся при этом отдельно, это связано с тем, что их размер заранее не
определен и может меняться, тогда как записи в таблице должны быть фиксированного размера.

Для того, чтобы избежать ненужного копирования, множество посещенных состояний \Code{Visited}
объединяется с \Code{Queue}. Новое состояние проверяется на вхождение в хэш-таблицу сразу при
генерации, и в случае отсутствия добавляется в \Code{Queue}. Таким образом, все попадающие в
\Code{Queue} состояния рано или поздно перейдут в \Code{Visited}, поэтому они занимают один
последовательный блок памяти, как это показано на рис.~\ref{fig:fullstate}. Новые состояния
добавляются в верхнюю часть \Code{Queue}, при этом указатель на начало свободной области сдвигается
вверх. Выборка состояний из \Code{Queue} делается с низу очереди, при этом указатель на ее начало
сдвигается (и состояние <<переносится>> в \Code{Visited}). Если свободная область памяти
заканчивается, алгоритм завершается с ошибкой.

\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{../graphics/fullstate}
  \caption{Хранение состояний при полном хэшировании}
  \label{fig:fullstate}
\end{figure}

\subsection{Битовое хэширование}
\label{sec:bithash-store}

При битовом хэшировании состояния после добавления в хэш-таблицу отбрасываются и занимаемая ими
память используется для хранения следующих состояний. Поэтому множество \Code{Visited} как таковое
отсутствует (оно представлено целиком в вид хэш-таблицы, которая и занимает при этом почти весь
доступный объем памяти). Сами состояния хранятся лишь в очередь \Code{Queue}.

Новые состояния добавляются в верхнюю часть очереди, при этом указатель на начало
свободной области сдвигается вверх. Однако, в отличие от алгоритма при полном хэшировании,
выборка состояний также делается с верху \Code{Queue} (т.е. она работает, как
стек). Поэтому при выборке состояние наверху очереди копируется в отдельное место
(например, в конец свободной области, как показано на рис.~\ref{fig:bitstate}), а его
прежняя область памяти затирается следующим добавляемым состоянием.

Объем памяти, который необходимо отвести под \Code{Queue}, сильно зависит от модели: в
каких-то моделях очередь может достигать большой длины, в каких-то она практически не
растет.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.7\textwidth]{../graphics/bitstate}  
  \caption{Хранение состояний при битовом хэшировании}
  \label{fig:bitstate}
\end{figure}

\subsection{Организация взаимодействия узлов}

В качестве платформы параллельных вычислений используется MPI.

MPI предоставляет следующий набор примитивов взаимодействия.

\begin{enumerate}
\item Синхронная передача сообщений. Делающий вызов процесс ожидает, пока сообщение не
  будет доставлено \emph{и} прочитано получателем.
\item Блокирующая передача сообщений. Делающий вызов процесс ожидает, пока сообщение будет
  отправлено получателю (при этом его доставка не имеет значения).
\item Асинхронная передача сообщений. Управление возвращается процессу немедленно,
  передача происходит в фоновом режиме.
\item Активный удаленный доступ к памяти (Active RMA). Каждый процесс создает
  \Term{окно}~--- раздел памяти для всеобщего доступа, при этом один процесс может
  обращаться к окнам других процессов при помощи специальных вызовов.
\item Пассивный удаленный доступ к памяти (Passive RMA). Аналогично active RMA, но со
  принимающего данные процесса не требуется какого либо участия.
\end{enumerate}

Синхронная передача очевидно не подходит, поскольку ожидание доставки будет лишней
задержкой в работе, так что из первых трех методов оптимальной является асинхронная
передача.

Наиболее привлекательным выглядит механизм passive RMA, поскольку от принимающего процесса не
требуется каких-либо действий по приему сообщения в очередь, а именно такому поведению соответствует
описанный алгоритм. Однако, RMA, хоть и является более простым в использовании, на современных
реализациях MPI работает медленнее, чем остальные примитивы~--- это связано с сложностью
синхронизации доступа к памяти окнаи с организацией приема данных на пассивной стороне. Например,
сравнение примитивов для реализации Intel MPICH, полученное при помощи утилиты \texttt{mpibench},
показывает, что passive RMA почти на порядок медленнее асинхронной передачи сообщений, а active
RMA~--- примерно в 5 раз. Поскольку ожидается, что задержки на передачу сообщений будут составлять
существенную часть времени генерации, в качестве используемого примитива была выбрана асинхронная
передача-прием сообщений, несмотря на удобство RMA.

\paragraph{Схема асинхронного обмена сообщениями}

После того, как буфер с данными отправлен вызовом \Code{Isend}, его нельзя вторично
использовать, пока сообщение не будет доставлено~--- необходимо дождаться завершения
операции доставки. Поэтому используется набор из $Q_1$ предвыделенных буферов (оптимальное
значение $Q_1$ необходимо выбирать, исходя из параметров кластера, скорости работы
сети\etc).

Отправка сообщения происходит следующим образом.
\begin{enumerate}
\item Выбирается первый свободный буфер (не помеченный как участвующий в асинхронной
  операции).
\item Усли такой буфер не найден~--- делается вызов \Code{Waitany} по всему набору
  буферов, который возвращает управление, как только хотя бы одна из операций завершится;
\item Операции по некоторым буферам уже могли завершиться к этому моменту~--- в этом
  случае \Code{Waitany} возвращает управление немедленно, помечая первый из таких буферов
  как свободный; при этом может больше одной завершившейся операции, и, чтобы избежать
  повторных вызовов \Code{Waitany} при посылке следующих сообщений, \Code{Testany}
  вызывается в цикле, пока все такие буфера не будут помечены освобожденными.
\item Передавемое состояние копируется в буфер.
\item Делается вызов \Code{Isend}, запускающий асинхронную передачу, и буфер помечается
  используемым.
\end{enumerate}

Описанный алгоритм отправки изображен в виде блок-схемы на рис.~\ref{fig:mpi-send-flowchart}.

\begin{figure}[!tb]
  \centering
  \includegraphics[height=0.8\textheight]{../graphics/mpi-send-flowchart}
  \caption{Блок-схема алгоритма отправки сообщения}
  \label{fig:mpi-send-flowchart}
\end{figure}

Для приема сообщений используется другой набор из $Q_2$ буферов (для простоты используется
одно и то же $Q_1 = Q_2 = Q$). Каждый из них предварительно передается в вызов
\Code{Irecv}, таким образом, запускается сразу $Q_2$ операций асинхронного приема. Прием
сообщения делается следующим образом:
\begin{enumerate}
\item делается вызов \Code{Waitany}, возвращающий управление, когда хотя бы одна из
  операций приема завершится;
\item по аналогии с приемом, \Code{Waitany} может вернуть управление сразу;
\item производится работа с принятым буфером;
\item когда буфер больше не нужен, делается вызов \Code{Irecv}, запускающий очередную
  операцию приема.
\end{enumerate}

Возможен также вариант приема сообщения без ожидания, когда вместо \Code{Waitany} используется
\Code{Testany}, проверяющий, нет ли уже завершенных операций приема.

Наборы буферов приема-отправки выделены в отдельные высокоуровневые примитивы (асинхронные
очереди MPI) с отдельными функциями для работы с ними.

Описанная схема асинхронного взаимодействия двух процессов показана в виде диаграммы
последовательностей на рис.~\ref{fig:mpi-async-seq}. Здесь \Code{P1} и \Code{P2}~--- два
взаимодействующих процесса на разных узлах, один показан в роли отправителя, другой~--- в роли
приемника. \Code{C1} и \Code{C2}~--- их MPI-коммуникаторы, а \Code{Q1} и \Code{Q2} представляют
собой описанные выше асинхронные очереди.

\begin{figure}[ht]
  \centering
  \includegraphics[width=1.1\textwidth]{../graphics/mpi-async-seq}  
  \caption{Асинхронное взаимодействие узлов (MPI)}
  \label{fig:mpi-async-seq}
\end{figure}

\subsection{Локальная и сетевая очереди состояний}

В описании приема сообщений не сказано, в какие именно моменты происходит прием MPI-сообщений. В
псевдокоде алгоритма есть операция выборки следующего состояния из очереди, \Code{Queue
  $\rightarrow$ state}.

В реальности, у какждого узла фактически есть две очереди: локальная очередь \Code{Queue$_L$}, куда
делается вставка новых локально сгенерированных состояний, и неявная сетевая очередь
\Code{Queue$_N$}, представленная набором MPI--буферов (неявная потому, что какой-либо порядок
добавления--выборки в ней отсутствует).

При отправке состояния другому узлу оно вставляется в его сетевую очередь, а при выборке надо
использовать обе очереди. Можно предложить два варианта опроса сетевой очереди:
\begin{enumerate}
\item всегда сначала выбирать состояние из локальной очереди; если локальная очередь закончилась,
  ожидать появления состояний в сетевой и выбирать из нее;
\item проверять сначала сетевую очередь на предмет наличия в ней сообщения; если их нет, проверять
  локальную; если обе пусты, ожидать появления сообщений в сетевой.
\end{enumerate}

Оба метода имеют свои достоинства и недостатки. При небольшом количестве узлов локальная очередь
состояний на отдельном узле может довольно долго не опустевать~--- если каждое состояние порождает
несколько новых, и хотя бы одно из них принадлежит текущему узлу. Тогда, если сначала опрашивается
локальная очередь, сообщения подолгу не будут приниматься этим узлом, а у других узлов, по мере
посылки ему сообщений, будут скапливаться незавершенные операции.

Прием сообщений сначала из \Code{Queue$_N$} может приводить к большому росту \Code{Queue$_L$}. При
\Code{полном хэшировании} размер \Code{Queue$_L$} не играет значения: \Code{Queue$_L$} и
\Code{Visited} хранятся в одной области памяти, поэтому порядок добавления в \Code{Queue$_L$} ничего
не меняет: все добавленные в нее состояния рано или поздно будут перенесены в \Code{Visited}. При
\Code{битовом хэшировании} состояния не хранятся нигде вне обоих очередей, и под \Code{Queue$_L$}
отводится отдельная область памяти, увеличение размера которой приводит к уменьшению размера
хэш-таблицы.

Для того, чтобы минимизировать сетевые задержки, предпочтение отдается второму варианту: сначала
проверяется сетевая очередь. Псевдокод алгоритма, с приведенными уточнениями, имеет вид:

\begin{lstlisting}[style=pseudocode]
Visited = []
QueueL  = []
QueueN  = []

def NextState():
    if not empty(QueueN):
        QueueN -> NextState
    elif not empty(QueueL):
        QueueL -> NextState
    else:
        wait(QueueN)
        QueueN -> NextState

def ParStateSpaceBFS():
    state = initial_state
    do:
        node = StateNode(state)
        if NodeId = node:
            if not state in Visited:
                Visited <- state
                for each new_state in Next(state):
                    QueueL <- new_state
        else:
            node.QueueN <- state
        state = NextState()

ParStateSpaceBFS()
\end{lstlisting}

Возможны две схемы использования состояния, взятых из сетевой очереди \Code{Queue$_N$}: скопировать
их в отдельную область памяти (например, в \Code{Queue$_L$}), после чего сразу отдать буфер обратно
в асинхронную очередь, либо использовать состояние прямо в буфере и отдать его после завершение
обработки состояния.

При полном хэшировании состояний вторая схема неприменима: в этом случае в хэш-таблицу будет
добавлен указатель на состояние в MPI-буфере, а не в \Code{Visited}, куда состояние будет перенесено
после обработки. Поэтому при полном хэшировании всегда используется первая схема, тогда как при
битовом можно выбрать любую из двух (одна обеспечивает меньший размер \Code{Queue$_L$}, другая~---
меньшие сетевые задержкие).

\subsection{Распределенное завершение работы}

Приведенный выше алгоритм не содержит в себе никакого условия завершения. Задача
обнаружения завершения в параллельных расчетах без разделяемой памяти является
нетривиальной: в условиях отсутствия средств атомарного опроса всех остальных узлов
необходим алгоритм, который бы позволил хотя бы одному узлу определить, что вычисления
завершились на всех узлах \emph{и} никаких отправленных, но еще не принятых сообщений в
системе нет.

\paragraph{Наивное решение}

Наивное решение задачи заключается в том, чтобы ввести на каждом узле $i$ счетчик $C_i$
сообщений, находящихся в пути. Изначально во всех узлах этот счетчик равен $0$, при
отправке сообщения другому узлу он увеличивается на $1$, при приеме~--- уменьшается на
$1$. Сумма счетчиков всех узлов $\sum_iC_i$ в выбранный момент времени есть число
находящихся в пути сообщений. Для подсчета этой суммы на каждом узле вводится
дополнительный счетчик-аккумулятор $A_i$. Первый узел инициализирует его значением $C_i$ и
передает первому узлу. Когда первый узел завершает всю локальную обработку и входит в
состояние простое, он прибавляет к аккумулятору $C_1$ и передает второму\etc. Последний
узел, завершив работу, передает обратно первому $A_N = \sum_iC_i$ и, если это значение
равно нулю, первый узел делает вывод, что сообщений в пути нет и оповещает всех остальных
о завершении. В противном случае ($A_N \neq 0$), первый узел отправляет второму новый
счетчик-аккумулятор, и процесс повторяется заново.

Такой <<наивный>> подход неправильно работает при сценарии, показанном на
рис.~\ref{fig:termination-naive}. Контрольные сообщения, содержащие счетчик-аккумулятор, показаны
курсивом, рядом с ними показано значение этого счетчика. Поскольку узел 3 отправил состояние,
которое еще не было получено узлом 2 в момент <<прохождения>> через него аккумулятора, а узел 4
успел принять сообщение от узла 2 до приема аккумулятора, суммарное число сообщений выходит
нулевым. Сообщения, посланные узлу 2 от узла 3 и узлу 4 от узла 2, не вошли в этот аккумулятор, в
результате чего завершение будет обнаружено узлом 1 неверно~--- узел 2, получивший новое сообщение
уже после отправки аккумулятора, может продолжать его обработку в момент объявления завершения.

\begin{figure}[htb]
  \centering
  \includegraphics[width=1\textwidth]{../graphics/termination-naive}  
  \caption{Наивное решение задачи распределенного завершения}
\label{fig:termination-naive}
\end{figure}

\paragraph{Алгоритм Дейкстры распределенного завершения}

Для решения возникающей проблемы предлагается алгоритм, впервые описанный Дейкстрой. Идея
его заключается в том, что каждому узлу приписывается цвет (в оригинале~--- белый и
черный, здесь мы будем называть их красный и синий). Цвет также приписывается
аккумулятору, передаваемому между узлами.

Цвет определяется следующими правилами:
\begin{enumerate}
\item когда узел принимает новое сообщение и начинает его обработку~--- он становится красным;
\item когда узел отправляет аккумулятор следующему узлу~--- он становится синим;
\item первый узел отправляет синий аккумулятор;
\item когда красный узел отправляет аккумулятор, последний также становится красным.
\end{enumerate}

Распределенное завершение обнаруживается первым узлом, если принятый от последнего узла
аккумулятор~--- синий. Это означает, что ни один узел не занимался обработкой на протяжении участка
времени от предпоследней до последней отправки аккумулятора и, следовательно, во время последнего
<<витка>> аккумулятора ни один узел не посылал новых сообщений. Наглядно работа этого алгоритма для
того же сценария продемонстрирована на рис.~\ref{fig:termination-dijkstra}.

\begin{figure}[htb]
  \centering
  \includegraphics[width=1\textwidth]{../graphics/termination-dijkstra}  
  \caption{Алгоритм Дейкстры распределенного завершения}
\label{fig:termination-dijkstra}
\end{figure}

\subsection{Журналирование работы системы}

Для отладки параллельной программы необходима возможность отладочного
журналирования. Поскольку при отладке высокая производительность не требуется,
используется простой способ: при запуске в отладочной конфигурации один из узлов
используется как служба журналирования. Остальные узлы вместо непосредственного вывода
отладочных сообщений в файл посылают их в виде сообщений службе журналирования, который
находится в постоянном цикле приема таких сообщений и выводит их в журнал.

\subsection{Формат сообщений}

Каждое сообщение в MPI, помимо данных, содержит тег (MPI tag), который может использоваться, как
идентификатор типа сообщения. В частности, возможен прием лишь сообщений с конкретным тегом, однако
данная функция используется лишь службой журналирования (который не принимает никаких сообщений,
кроме отладочного вывода).

Всего используется 4 типа сообщений, каждое имееющее свой тег.
\begin{itemize}
\item Сообщение с новым состоянием. Содержит состояние в виде массива байт
  (\Code{MPI\_CHAR}).
\item Сообщение с счетчиком-аккумулятором (для обнаружения завершения). Содержит 2 элемента
  \Code{MPI\_INT}: счетчик и его цвет (0~--- синий, 1~--- красный).
\item Сообщение с объявлением о завершении. Рассылается всем остальным узлам, когда какой-то узел
  обнаруживает завершение (это может быть первый узел, если завершение обнаружено алгоритмом
  Дейкстры, или любой другой, если завершение происходит из-за нахождения контпримера
  $\pi_e$). Состоит из одного элемента \Code{MPI\_INT}~--- номера узла, обнаружившего завершение.
\item Сообщение с отладочным выводом. Должно посылаться лишь узлу со службой журналирования и
  обрабатывается лишь им. Содержит строку в виде символьного массива (\Code{MPI\_CHAR}).
\end{itemize}

В качестве нотации, используемой для задания модели, выбрано подмножество языка \Code{Promela},
используемого в ПО \Code{Spin}. Это позволяет использовать модели, созданные для \Code{Spin}, с
минимальными изменениями. По аналогии со Spin, исходное описание модели считывается синтаксическим
анализатором и переводится во внутреннее представление в виде графа команд и условий их
выполнимости, из которого генерируется код на~С, релализующий функцию $Next(s)$ для алгоритма
генерации состояний.

\section{Оценка и сравнение со Spin}

Для экспериментов использовался кластер~МГТУ, состоящий из 102 вычислительных
узлов. Каждый узел имеет 4 процессора Intel\regsign Xeon\regsign~5120 с тактовой частотой
$1.86$~ГГц и 4 Гб оперативной памяти; узлы соединены 10-гигабитной шиной Infiniband. На
узлах установлена ОС RHEL~5.3 и библиотека Intel~MPI~3.1.

В качестве моделей для экспериментов выбрано две модели, описанных в~\cite{SPIN}: модель
обедающих философов \Code{Philo} и алгоритм выбора лидера \Code{Election}.

В модели \Code{Philo} все процессы одинаковы и не имеют переменных, кроме счетчика инструкций,
принимающего $24$ значения. Данная модель специально выбрана как неудачный случай для используемого
распределения состояний из-за отсутствия локальных переменных. !!!$\Omega_i = 24$ в этом случае,
поэтому при использовании лишь $\rho = 1$ одного процесса для распределения количество узлов не
может превышать 24; при использовании 2 процессов можно ожидать большей равномерности распределения.

Модель \Code{Election} также состоит из $P$ одинаковых процессов, каждый из которых имеет 6
локальных переменных и счетчик инструкций, принимающий 32 значения. Переменные могут принимать $12 P
(P-1)$ значений, поэтому $\Omega_i = 384\cdot P (P - 1)$. Это позволяет ожидать лучшего
распределения уже при $\rho = 1$.

\subsection{Зависимость количества состояний от времени}

В данном эксперименте оценивалось время генерации пространства состояний разработанным ПО и
существующим ПО Spin. Поскольку Spin реализует последовательную генерацию состояний, он запускается
лишь на одном узле.

Запуск разработанного ПО производится на наборе от 8 до 80 узлов в двух режимах:
\begin{enumerate}
\item использование полного хэширование с коллизиями; в этом случае число узлов выбиралось
  так, чтобы средняя загрузка хэш-таблицы не превышала 70\%;
\item использование битового хэширования с $k = 3$ хэш-функциями; число узлов выбиралось таким,
  чтобы обеспечить ожидаемое покрытие в соответствии с формулой~(\ref{eq:bithash-multi-coll1}) не
  менее 99\%.
\end{enumerate}

На графике~\ref{fig:states-speed} по оси абсцисс показано количество состояний модели, по
оси ординат~--- время генерации.

\begin{figure}[ht]
  \centering
  \includegraphics[width=1\textwidth]{../data/plots/states-speed}
  \caption{Зависимость времени генерации от числа состояний}
  \label{fig:states-speed}
\end{figure}

При моделях с небольшим размером пространства состояний, до $10^7$, памяти одной машины
достаточно для хранения всего множесва посещенных состояний. В этом диапазоне время работы
ПО Spin и разработанного сравнимы. Модели с числом состояний $10^7-10^8$ уже невозможно
проверить последовательной генерацией, поэтому приведены данные лишь для
параллельной. 

Поскольку имевшееся в распоряжении количество узлов кластера ограничено (100, на практике
до 80), для проверки модели, имеющих $10^9$ и больше состояний, необходимо использовать
битовое хэширование с потерей состояний. Это позволяет сгенерировать почти $10^{11}$
состояний, после чего ожидаемое покрытие становится меньше 99\% при использовании 80
узлов.

\subsection{Сравнение распределения состояний}

В данном эксперименте сравниваются 3 схемы распределения состояний: хэшированием всего состояния и
хэшированием первых $\rho$ процессов при $\rho = 1$ и $\rho = 2$. Используются модели \Code{Philo} с
$P = 6$ и \Code{Election} с $P = 8$, запуск производится на 8 узлах.

На рис.~\ref{fig:state-partition1} и~\ref{fig:state-partition2} приведены результаты по двум срезам:
модели и схеме распределения. Сраниваются следующие четыре фактора:
\begin{enumerate}
\item доля переходов, приводящих к посылке сообщения другому узлу; усредняется по всем узлам;
\item неравномерность распределения состояний между узлами как отношение среднеквадратичного
  отклонения числа состояний к среднему значению по всем узлам;
\item время, которое узел проводит в ожидании приема сообщения (сетевые задержки); сюда также входит
  описанное в разделе ожидание доставки сообщения, когда все исходящие буфера заняты; усредняется по
  всем узлам;
\item суммарное время выполнения (одно для всех узлов);
\end{enumerate}

\begin{figure}[p]
  \centering
  \includegraphics[width=2\textwidth]{../data/plots/state-partition1}
  \caption{Распределение состояний между узлами; срез по модели}
  \label{fig:state-partition1}
\end{figure}

\begin{figure}[p]
  \centering
  \includegraphics[height=0.9\textheight]{../data/plots/state-partition2}
  \caption{Распределение состояний между узлами; срез по типу распределения}
  \label{fig:state-partition2}
\end{figure}

При использовании хэша всего состояния (справа на рис.~\ref{fig:state-partition1}) неравномерность
распределения достигает лишь 0.1\% в обоих случаях, однако число сообщений близко к числу всех
переходов (до 90\%), в результате чего, как и ожидалось, время выполнения очень велико; большую
часть времени узлы простаивают, ожидая состояний друг от друга.

!!!
При распределении по $\rho = 1$ процессу число удаленных вызовов составляет порядка 16--20\% от
числа всех переходов, что находится в согласии с
формулой~(\ref{eq:nmsg-firstproc-hash}). Неравномерность распределения при этом для \Code{Election}
составляет 65\%, а для \Code{Philo}~--- 90\%, что подтверждает изначальное предположение.

Распределение по $\rho = 2$ процессам представляет собой компромисс между временем и равномерностью:
для модели \Code{Philo} неравномерность, как и ожидается, по-прежнему велика и составляет 30\%, для
\Code{Election}~--- всего 10\%. Последнюю цифру можно считать приемлемой, так как это означает, что
трата памяти узла не превышает 10\% с вероятностью $\alpha = \Phi^{-1}(1) = 83\%$. Число сообщений и
время простоя при этом в 2 раза больше, чем в предыдущем случае, но в 2--3 раза меньше, чем при
равномерном распределении.

Следует отметить, что время простоя составляет б\'{о}льшую часть времени выполнения, особенно при
равномерном распределении, поэтому изначальное предположение о важности выбора распределения для
времени проверки свойств модели было верным.

!!! переписать
\section*{Выводы из экспериментов}

Следует отметить, что ввиду ограниченного объема работы не применяется какое-либо сжатие или
упаковка состояний, что приводит к расходу лишнего объема памяти и делает затруднительной работу на
платформах, где требуется обязательного выраванивание данных, например, MIPS. Более того, передача
состояний между узлами осуществляется также без какого-либо перевода в архитектурно-независимую
форму (вроде пользователького MPI-типа или JSON-объекта). Это означает, что все узлы должны иметь
одинаковую архитектуру (гомогенная вычислительная сеть). Обычно промышленные кластеры являются
гомогенными, поэтому этот недостаток не является критичным.

\begin{enumerate}
\item Разработанное ПО может использоваться для проверки моделей с б\'{о}льшим числом
  состояний, чем позволяет существующее ПО с последовательной генерацией состояний;
\item скорость генерации состояний сравнима со скоростью в существующем ПО Spin;
\item выбор распределения между узлами важен, поскольку время простоя за счет удаленных
  вызовов составляет б\'{о}льшую часть от времени выполнения;
\item разработанный способ распределения состояний позволяет в 2--3 раза уменьшить число
  удаленных вызовов и время выполнения при неравномерности распределения не выше 30\%.
\end{enumerate}

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
